### UCB - AIML Capstone Project: Heart Attack Analysis and Prediction### Executive Summary**Project Overview and Goals:**The goal of this project is to predict the likelihood of heart attack occurrence in patients using machine learning models based on various health metrics and medical history data. By accurately identifying high-risk individuals, healthcare providers can take preventative measures and provide timely interventions. We will train and evaluate multiple machine learning models to determine the most effective one for predicting heart attack risk.### Table of Contents1. [Dataset Information](#dataset-information)2. [Data Preparation](#data-preparation)3. [Exploratory Data Analysis (EDA)](#exploratory-data-analysis-eda)4. [Modeling and Evaluation](#modeling-and-evaluation)5. [Results](#results)6. [Conclusion and Future Work](#conclusion-and-future-work)7. [References](#references)### Dataset Information**Source:**The dataset used in this project is obtained from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/heart+disease) and is publicly available on [Kaggle](https://www.kaggle.com/code/oaktechacademy/up-to-date-heart-attack-analysis-and-prediction).**Structure:**The dataset includes the following attributes:- **Age**: Age of the patient- **Sex**: Gender of the patient (1 = male, 0 = female)- **Chest Pain Type (cp)**: Categorized as 0-3- **Resting Blood Pressure (trestbps)**: In mm Hg on admission to the hospital- **Cholesterol (chol)**: Serum cholesterol in mg/dl- **Fasting Blood Sugar (fbs)**: If > 120 mg/dl (1 = true, 0 = false)- **Resting Electrocardiographic Results (restecg)**: Categorized as 0-2- **Max Heart Rate Achieved (thalach)**- **Exercise-Induced Angina (exang)**: 1 = yes, 0 = no- **Oldpeak**: ST depression induced by exercise relative to rest- **Slope**: Slope of the peak exercise ST segment- **Number of Major Vessels (ca)**: Colored by fluoroscopy (0-3)- **Thal**: 3 = normal, 6 = fixed defect, 7 = reversible defect- **Target (target)**: 1 = presence of heart disease, 0 = absence of heart disease### Data Preparation**Steps:**1. **Data Cleaning:** Handled missing values and encoded categorical variables.2. **Feature Scaling:** Scaled numerical features to ensure consistency for model training.3. **Train-Test Split:** Divided the dataset into training (70%) and test sets (30%).### Exploratory Data Analysis (EDA)**Techniques Used:**- **Descriptive Statistics:** Summarized the central tendency, dispersion, and shape of the datasetâ€™s distribution.- **Correlation Matrix:** Examined relationships between features to identify multicollinearity.- **Visualizations:** Histograms, box plots, and scatter plots to understand the distribution and relationships among features.### Modeling and Evaluation**Models Trained:**1. **Logistic Regression**2. **Decision Trees**3. **K-Nearest Neighbors (KNN)**4. **Support Vector Machines (SVM)**5. **Random Forest**6. **Gradient Boosting****Evaluation Metrics:**- **Accuracy**- **Precision**- **Recall**- **F1-Score**- **Confusion Matrix**- **Mean Squared Error (MSE)****Model Performance:**| Model                | Train Score | Test Score | Mean Fit Time | Accuracy | Precision | Recall  | Specificity | Train MSE | Test MSE ||----------------------|-------------|------------|---------------|----------|-----------|---------|-------------|-----------|----------|| Logistic Regression  | 0.5958      | 0.5971     | 0.24 seconds  | 59.43%   | 56.14%    | 85.10%  | 33.91%      | 0.4032    | 0.4010   || Decision Tree        | 0.5921      | 0.5917     | 0.37 seconds  | 75.92%   | 72.76%    | 82.64%  | 69.24%      | 0.1879    | 0.2387   || K-Nearest Neighbors  | 0.7644      | 0.7295     | 0.21 seconds  | 72.41%   | 69.89%    | 78.44%  | 66.41%      | 0.2356    | 0.2705   || Support Vector Machine| 0.6339     | 0.6401     | 3.72 seconds  | 62.34%   | 58.03%    | 77.48%  | 48.40%      | 0.3684    | 0.3740   |### Results**Key Findings:**- **Logistic Regression:** High recall (85.10%), useful for identifying as many potential cases as possible, despite lower precision and specificity.- **Decision Tree:** Best overall performance with balanced accuracy (75.92%), precision (72.76%), recall (82.64%), and specificity (69.24%).- **K-Nearest Neighbors:** Good overall performance, slightly lower specificity.- **Support Vector Machine:** Longest training time, moderate performance.### Conclusion and Future Work**Conclusion:**The Decision Tree model offers the best balance of accuracy, precision, recall, and specificity, making it the most suitable model for deployment in predicting heart attack risk.**Future Work:**1. **Hyperparameter Tuning:** Further optimize models using Grid Search or Randomized Search.2. **Ensemble Methods:** Explore techniques like Random Forests or Gradient Boosting to improve performance.3. **Data Augmentation:** Use techniques like SMOTE to balance the dataset and improve minority class predictions.4. **Regular Monitoring:** Continuously monitor and retrain the model with new data to maintain accuracy and adapt to changing patient profiles.### References- [Up-to-date Heart Attack Analysis And Prediction](https://www.kaggle.com/code/oaktechacademy/up-to-date-heart-attack-analysis-and-prediction)- [Heart Disease Data Set](https://archive.ics.uci.edu/ml/datasets/heart+disease)---This README provides a comprehensive overview of the heart attack analysis and prediction project, including dataset details, methodology, results, and future directions.